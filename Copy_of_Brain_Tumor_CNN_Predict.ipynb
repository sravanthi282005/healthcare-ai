{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c4505e69",
      "metadata": {
        "id": "c4505e69"
      },
      "source": [
        "# Brain tumor detection using a CNN - Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adce89d1",
      "metadata": {
        "id": "adce89d1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, LeakyReLU, BatchNormalization, Dropout, Dense, InputLayer, Flatten, RandomFlip\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75049fe0",
      "metadata": {
        "id": "75049fe0"
      },
      "source": [
        "Run this cell only if you are working on **Google Collab**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec2d19e5",
      "metadata": {
        "id": "ec2d19e5"
      },
      "outputs": [],
      "source": [
        "import urllib\n",
        "import zipfile\n",
        "import os\n",
        "# Download and unzip the dataset\n",
        "if not os.path.isfile('.zip'):\n",
        "  urllib.request.urlretrieve(\"https://github.com/Gurupatil0003/Brain-Tumor-Data-Set/archive/refs/heads/main.zip\", \"Brain Tumor Data Set.zip\")\n",
        "\n",
        "zip_filename = \"Brain Tumor Data Set.zip\"\n",
        "with zipfile.ZipFile(\"Brain Tumor Data Set.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\".\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "base_dir = \"/content/Brain-Tumor-Data-Set-main/Brain Tumor Data Set\"\n",
        "train_dir = os.path.join(base_dir, \"Train\")\n",
        "test_dir = os.path.join(base_dir, \"Test\")\n"
      ],
      "metadata": {
        "id": "pcoEmdTMWK9t"
      },
      "id": "pcoEmdTMWK9t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image settings\n",
        "img_size = (150, 150)\n",
        "batch_size = 32\n",
        "\n",
        "# Data generators\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, zoom_range=0.2, shear_range=0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "id": "XqARu1lYWXay",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ea061e2-c305-4c30-b1a3-ab8862a450e6"
      },
      "id": "XqARu1lYWXay",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3903 images belonging to 2 classes.\n",
            "Found 950 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_data, epochs=1, validation_data=test_data)"
      ],
      "metadata": {
        "id": "8x_EToUYWbI9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "849198d3-cfcc-4573-af48-8fc4258add34"
      },
      "id": "8x_EToUYWbI9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 2s/step - accuracy: 0.5859 - loss: 0.6891 - val_accuracy: 0.7632 - val_loss: 0.5268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "loss, accuracy = model.evaluate(test_data)\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "# Save model\n",
        "model.save(\"brain_tumor_cnn_model.h5\")\n"
      ],
      "metadata": {
        "id": "ZObYvSxdsSRn",
        "outputId": "eb155f38-e0e4-4a3f-b2f5-17d109fcea2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZObYvSxdsSRn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3903 images belonging to 2 classes.\n",
            "Found 950 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 2s/step - accuracy: 0.6186 - loss: 0.6569 - val_accuracy: 0.7495 - val_loss: 0.5030\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 452ms/step - accuracy: 0.7451 - loss: 0.5081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 74.95%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check its architecture\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "iyeFmN_kImuo"
      },
      "id": "iyeFmN_kImuo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UI Interface"
      ],
      "metadata": {
        "id": "t-7hue1IW6SW"
      },
      "id": "t-7hue1IW6SW"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "-olHq8B4IjIS"
      },
      "id": "-olHq8B4IjIS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load the trained model\n",
        "model = tf.keras.models.load_model(\"brain_tumor_cnn_model.h5\")\n",
        "\n",
        "# Preprocessing function\n",
        "def predict_tumor(img):\n",
        "    img = img.resize((150, 150))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = img_array / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    prediction = model.predict(img_array)[0][0]\n",
        "    return \"Cancer\" if prediction > 0.5 else \"Non-Cancer\"\n",
        "\n",
        "# Gradio Interface\n",
        "interface = gr.Interface(\n",
        "    fn=predict_tumor,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=gr.Text(label=\"Prediction\"),\n",
        "    title=\"Brain Tumor Detector\",\n",
        "    description=\"Upload an MRI scan image to check for brain tumor (Cancer/Non-Cancer)\"\n",
        ")\n",
        "\n",
        "interface.launch()"
      ],
      "metadata": {
        "id": "Ps2BFjNcuWq2",
        "outputId": "ce452817-a51e-4ef3-d181-738d2f9dbd0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        }
      },
      "id": "Ps2BFjNcuWq2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://9ca111de304110e5b9.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9ca111de304110e5b9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}